{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I want to explore the Prophet package for forecasting. \n",
    "Underneath the hood this procedure uses Additive Regression.\n",
    "There are four components: \n",
    "a piecewise linear or logistic growth curve trend. Prophet automatically detects changes in trends by selecting changepoints from the data.\n",
    "\n",
    "A yearly seasonal component is modeled using Fourier series.\n",
    "\n",
    "A weekly seasonal component using dummy variables.\n",
    "\n",
    "(Source: https://peerj.com/preprints/3190.pdf) \n",
    "\n",
    "Users can define a list of holidays, modeling future uncertainty with seasonality or holiday effects, we can run a few hundred Hamiltonian Monte Carlo iterations, to include this seasonal uncertainty estimates. \n",
    "\n",
    "\n",
    "The model uses the Stan probabilistic programming language. Stan performs the MAP (maximum a posteriori) optimization for parameters (recommended) or Hamiltonian Monte Carlo (not recommended due to poor convergence -Mark Conrad). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fbprophet import Prophet\n",
    "import os # directory traversal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/markconrad/Documents/Paccar/Deep_Learning/CFA_research/Data\n"
     ]
    }
   ],
   "source": [
    "cd Data/\n",
    "# MUST NOTE THAT MY FILES ARE FAIRLY DISORGANIZED!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"PCAR.csv\", encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prophet requires columns with the name ds (x) and y:\n",
    "df['ds'] = pd.to_datetime(df['Date'])\n",
    "# We care about the closing price for PCAR's stock.\n",
    "df['y'] = df['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"orig_y\"] = df['y']\n",
    "df[\"y\"] = np.log(df[\"y\"]) \n",
    "# # taking the log reduces the outcome space to the exponent of e to get the original number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>orig_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-12-13</td>\n",
       "      <td>44.630001</td>\n",
       "      <td>44.810001</td>\n",
       "      <td>43.840000</td>\n",
       "      <td>43.900002</td>\n",
       "      <td>37.961784</td>\n",
       "      <td>2048300</td>\n",
       "      <td>2012-12-13</td>\n",
       "      <td>3.636580</td>\n",
       "      <td>37.961784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-12-14</td>\n",
       "      <td>44.009998</td>\n",
       "      <td>44.450001</td>\n",
       "      <td>43.860001</td>\n",
       "      <td>43.910000</td>\n",
       "      <td>37.970425</td>\n",
       "      <td>1974800</td>\n",
       "      <td>2012-12-14</td>\n",
       "      <td>3.636808</td>\n",
       "      <td>37.970425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-12-17</td>\n",
       "      <td>44.169998</td>\n",
       "      <td>44.349998</td>\n",
       "      <td>43.840000</td>\n",
       "      <td>44.310001</td>\n",
       "      <td>38.316319</td>\n",
       "      <td>1964300</td>\n",
       "      <td>2012-12-17</td>\n",
       "      <td>3.645876</td>\n",
       "      <td>38.316319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-18</td>\n",
       "      <td>44.450001</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>44.290001</td>\n",
       "      <td>44.980000</td>\n",
       "      <td>38.895683</td>\n",
       "      <td>2025300</td>\n",
       "      <td>2012-12-18</td>\n",
       "      <td>3.660883</td>\n",
       "      <td>38.895683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>44.900002</td>\n",
       "      <td>45.439999</td>\n",
       "      <td>44.669998</td>\n",
       "      <td>44.939999</td>\n",
       "      <td>38.861092</td>\n",
       "      <td>2348600</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>3.659994</td>\n",
       "      <td>38.861092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close   Volume  \\\n",
       "0  2012-12-13  44.630001  44.810001  43.840000  43.900002  37.961784  2048300   \n",
       "1  2012-12-14  44.009998  44.450001  43.860001  43.910000  37.970425  1974800   \n",
       "2  2012-12-17  44.169998  44.349998  43.840000  44.310001  38.316319  1964300   \n",
       "3  2012-12-18  44.450001  45.000000  44.290001  44.980000  38.895683  2025300   \n",
       "4  2012-12-19  44.900002  45.439999  44.669998  44.939999  38.861092  2348600   \n",
       "\n",
       "          ds         y     orig_y  \n",
       "0 2012-12-13  3.636580  37.961784  \n",
       "1 2012-12-14  3.636808  37.970425  \n",
       "2 2012-12-17  3.645876  38.316319  \n",
       "3 2012-12-18  3.660883  38.895683  \n",
       "4 2012-12-19  3.659994  38.861092  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = df.rename(columns = {\"date 30 min\":\"ds\", \"lst trd /lst prce\":'y'})\n",
    "df[\"ds\"] = pd.DatetimeIndex(df[\"ds\"])\n",
    "# ax = df.set_index('ds').plot(df['ds'],df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslib.Timestamp"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[\"ds\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default Prophet only returns uncertainty in the trend and observation noise. To get uncertainty in seasonality, we must do full Bayesian sampling as noted in the Facebook documentation. This process replaces the typical MAP with Markov Chain Monte Carlo (MCMC).\n",
    "\n",
    "### Important background information\n",
    "MAP stands for Maximum a posteriori estimation: in Bayesian statistics, a MAP estimate is an estimate of an unknown quantity that equals the mode of the posterior distribution. This gives us a point estimate of an unobserved quantity based on observed empirical data. \n",
    "\n",
    "MAP is related to maximum likelihood (ML) estimation which is a special case of MAP that is defined as a process of estimating the parameters of a statistical model given observations, essentially finding the parameter values that maximize the likelihood of making the observations given the parameters, maxmizing the agreement between a set of observations and the selected model (Source: Wikipedia). \n",
    "\n",
    "MAP differs in that it employs an augmented optimization objective incorporating a prior distribution incorporating additional information available through prior knowledge of a related event. We can simplify this definition as employing ML estimation with regularization (Source: Wikipedia).\n",
    "\n",
    "MCMC employs a full sampling and we will then see the uncertainty in seasonal components, which is great, however, it is much slower than the MAP estimation algorithm (especially on Windows using Python). For best results use R on Windows and Python on Unix based operating system.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We initialize our Prophet model, mcmc stands for Markov Chain Monte Carlo (MCMC) method to generate its forecasts. MCMC is \n",
    "# a stochastic process giving us uncertainty intervals in our subplots.\n",
    "# HMC is awesome Stan's implementation from Gelman's team is really intriguing!\n",
    "# However, we will use the default MAP estimation instead due to time constraints.\n",
    "my_model = Prophet( interval_width=0.95)# Prophet(interval_width=.95, uncertainty_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model = Prophet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model = Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fbprophet.forecaster.Prophet at 0x119f79080>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit(df) # Very slow, we can specify how many MCMC to perform for the uncertainty intervals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "future = my_model.make_future_dataframe(periods = 365)\n",
    "forecast = my_model.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df['y_log']=df['y'] #copy the log-transformed data to another column\n",
    "df['y']=(df['orig_y']) #copy the original data to 'y'\n",
    "forecast_orig['yhat'] = np.exp(forecast_orig['yhat'])\n",
    "forecast_orig['yhat_lower'] = np.exp(forecast_orig['yhat_lower'])\n",
    "forecast_orig['yhat_upper'] = np.exp(forecast_orig['yhat_upper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.figure(1)\n",
    "# plt.xlabel(\"Time in Days\")\n",
    "# plt.ylabel(\"Adj Close\")\n",
    "forecast_orig = forecast\n",
    "\n",
    "my_model.plot((forecast_orig)).savefig(\"Conservative Bayes MCMC\", dpi = 2000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline \n",
    "# plt.plot((forecast[\"ds\"][-365:]),(np.exp(forecast[\"yhat\"][-365:])))\n",
    "x = np.arange(365)\n",
    "y = (forecast_orig[\"yhat\"][-365:])\n",
    "plt.figure(1)\n",
    "plt.plot(x, y, label = 'Predicted Adj Close')\n",
    "plt.ylabel(\"Adj Close\")\n",
    "plt.xlabel(\"Days in the future\")\n",
    "plt.title(\"Prophet (Generalized Additive Regression) Forecast\")\n",
    "plt.legend()\n",
    "plt.annotate('Credit to the Core Data Science Team at Facebook and Andrew Gelman for core libraries used.', (0,0), (0, -40), xycoords='axes fraction', textcoords='offset points', va='top')\n",
    "plt.savefig(\"Prophet_Forecast.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Prophet uses baked in l1 regularization. It has a large number of potential change points, at which the rate is allowed to change. It then puts a sparse prior (l1 regularization). Essentially Prophet will set a large number of change points and only use a subset of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default Prophet fits weekly and yearly seasonalities, it can even fit sub-daily time series. The model updates it's priors with new information, the default prior scaling is 10 which provides very little regularization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three sources of uncertainty in the trend, uncertainty in the seasonality estimates, and additional observation noise. The biggest source of uncertainty in the forecast is the potential for future trend changes. The model can effectively fit the trend changes, but how do we predict trends in the future? We can assume it will be similar to the past, in that we assume that the average frequency and magnitude of trend changes in the future will be the same as in the past. \n",
    "This assumption probably will not hold, thus the coverage of the confidence interval may not be entirely accurate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.93677487552416"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.exp(forecast['yhat'][-365:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we include earnings reports and holidays we can even more accurately the price of this stock. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model.plot_components(forecast).savefig(\"Conservative subplots\", dpi = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_data(func_df, end_date):\n",
    "    end_date = end_date - timedelta(weeks=4) # find the 2nd to last row in the data. We don't take the last row because we want the charted lines to connect\n",
    "    mask = (func_df.index > end_date) # set up a mask to pull out the predicted rows of data.\n",
    "    predict_df = func_df.loc[mask] # using the mask, we create a new dataframe with just the predicted data.\n",
    "   \n",
    "# Now...plot everything\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(sales_df.y_orig)\n",
    "    ax1.plot((np.exp(predict_df.yhat)), color='black', linestyle=':')\n",
    "    ax1.fill_between(predict_df.index, np.exp(predict_df['yhat_upper']), np.exp(predict_df['yhat_lower']), alpha=0.5, color='darkgray')\n",
    "    ax1.set_title('Sales (Orange) vs Sales Forecast (Black)')\n",
    "    ax1.set_ylabel('Dollar Sales')\n",
    "    ax1.set_xlabel('Date')\n",
    "  \n",
    "# change the legend text\n",
    "    L=ax1.legend() #get the legend\n",
    "    L.get_texts()[0].set_text('Actual Sales') #change the legend text for 1st plot\n",
    "    L.get_texts()[1].set_text('Forecasted Sales') #change the legend text for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
