{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to get into the Prophet package for forecasting. Underneath the hood this procedure uses Additive Regression.\n",
    "There are four components: a piecewise linear or logistic growth curve trend. Prophet automatically detects changes in trends by selecting changepoints from the data.\n",
    "\n",
    "A yearly seasonal component is modeled using Fourier series.\n",
    "\n",
    "A weekly seasonal component using dummy variables.\n",
    "\n",
    "Users can define a list of holidays, modeling future uncertainty with seasonality or holiday effects, we can run a few hundred Hamiltonian Monte Carlo iterations, to include this seasonal uncertainty estimates. \n",
    "\n",
    "The model uses the Stan probabilistic programming language. In the default implementation Stan performs the MAP (maximum a posteriori) optimization for parameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fbprophet import Prophet\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/max_years.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"y\"] = np.log(df[\"y\"]) \n",
    "# taking the log reduces the outcome space to the exponent of e to get the original number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/17/1980</td>\n",
       "      <td>-0.897103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/18/1980</td>\n",
       "      <td>-0.938299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/19/1980</td>\n",
       "      <td>-0.952415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/20/1980</td>\n",
       "      <td>-1.026161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/21/1980</td>\n",
       "      <td>-1.016009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds         y\n",
       "0  3/17/1980 -0.897103\n",
       "1  3/18/1980 -0.938299\n",
       "2  3/19/1980 -0.952415\n",
       "3  3/20/1980 -1.026161\n",
       "4  3/21/1980 -1.016009"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.rename(columns = {\"date 30 min\":\"ds\", \"lst trd /lst prce\":'y'})\n",
    "df[\"ds\"] = pd.DatetimeIndex(df[\"ds\"])\n",
    "# ax = df.set_index('ds').plot(df['ds'],df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslib.Timestamp"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[\"ds\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default Prophet only returns uncertainty in the trend and observation noise. To get uncertainty in seasonality, we must do full Bayesian sampling as noted in the Facebook documentation. This process replaces the typical MAP with Markov Chain Monte Carlo (MCMC).\n",
    "\n",
    "MAP stands for Maximum a posteriori estimation: in Bayesian statistics, a MAP estimate is an estimate of an unknown quantity that equals the mode of the posterior distribution. This gives us a point estimate of an unobserved quantity based on observed empirical data. \n",
    "\n",
    "MAP is related to maximum likelihood (ML) estimation which is a special case of MAP that is defined as a process of estimating the parameters of a statistical model given observations, essentially finding the parameter values that maximize the likelihood of making the observations given the parameters, maxmizing the agreement between a set of observations and the selected model (Source: Wikipedia). \n",
    "\n",
    "MAP differs in that it employs an augmented optimization objective incorporating a prior distribution incorporating additional information available through prior knowledge of a related event. We can simplify this definition as employing ML estimation with regularization.\n",
    "\n",
    "MCMC employs a full sampling and we will then see the uncertainty in seasonal components, which is great, however, it is much slower than the MAP estimation algorithm (especially on Windows using Python). For best results use R on Windows and Python on Unix based operating system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialize our Prophet model, mcmc stands for Markov Chain Monte Carlo (MCMC) method to generate its forecasts. MCMC is \n",
    "# a stochastic process giving us uncertainty intervals in our subplots.\n",
    "my_model = Prophet(interval_width= 0.95, mcmc_samples= 10000) # this will take a long time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    }
   ],
   "source": [
    "my_model.fit(df) # Very slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = my_model.make_future_dataframe(periods = 365)\n",
    "forecast = my_model.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = [col for col in forecast.columns if col not in 'ds']\n",
    "# forecast[cols] = np.log(forecast[cols])\n",
    "# forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.plot((forecast), uncertainty=True).savefig(\"Amos's Conservative Bayesian MCMC\", dpi = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prophet uses baked in l1 regularization. It has a large number of potential change points, at which the rate is allowed to change. It then puts a sparse prior (l1 regularization). Essentially Prophet will set a large number of change points and only use a subset of them (Source: https://research.fb.com/prophet-forecasting-at-scale/. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default Prophet fits weekly and yearly seasonalities, it can even fit sub-daily time series. The model updates it's priors with new information, the default prior scaling is 10 which provides very little regularization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three sources of uncertainty in the trend, uncertainty in the seasonality estimates, and additional observation noise. The biggest source of uncertainty in the forecast is the potential for future trend changes. The model can effectively fit the trend changes, but how do we predict trends in the future? We can assume it will be similar to the past, in that we assume that the average frequency and magnitude of trend changes in the future will be the same as in the past. \n",
    "This assumption probably will not hold, thus the coverage of the confidence interval may not be entirely accurate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.exp(forecast['yhat'][-365:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we include earnings reports and holidays we can even more accurately the price of this stock. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.plot_components(forecast).savefig(\"Conservative subplots\", dpi = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
